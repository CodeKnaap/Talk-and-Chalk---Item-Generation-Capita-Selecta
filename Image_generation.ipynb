{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963416c4-9419-4c8a-bf74-31ec55abbed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cut of gradio section, should result in a simple inputsketch and input prompt pair \n",
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "inputSketch = None\n",
    "inputPrompt = \"\"\n",
    "\n",
    "\n",
    "\n",
    "def sleep(im):\n",
    "    time.sleep(5)\n",
    "    return [im[\"background\"], im[\"layers\"][0], im[\"layers\"][1], im[\"composite\"]]\n",
    "\n",
    "def predict(im):\n",
    "    return im[\"composite\"]\n",
    "\n",
    "def submit(im, prompt):\n",
    "    global inputSketch\n",
    "    inputSketch = im\n",
    "    global inputPrompt\n",
    "    inputPrompt =  prompt\n",
    "    return \"prompt and sketch submited\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        im = gr.ImageEditor(\n",
    "            type=\"numpy\",\n",
    "            crop_size=\"1:1\",\n",
    "            height=512,  # Define sketch height\n",
    "            width=512    # Define sketch width\n",
    "        )\n",
    "        im_preview = gr.Image()\n",
    "    \n",
    "    with gr.Row():\n",
    "        userPrompt = gr.TextArea(label=\"input prompt:\")\n",
    "\n",
    "    with gr.Row():\n",
    "        submit_button = gr.Button(\"submbit\")\n",
    "\n",
    "    submit_button.click(fn= submit, inputs=[im_preview, userPrompt])\n",
    "\n",
    "    # n_upload = gr.Number(0, label=\"Number of upload events\", step=1)\n",
    "    # n_change = gr.Number(0, label=\"Number of change events\", step=1)\n",
    "    # n_input = gr.Number(0, label=\"Number of input events\", step=1)\n",
    "\n",
    "    # im.upload(lambda x: x + 1, outputs=n_upload, inputs=n_upload)\n",
    "    # im.change(lambda x: x + 1, outputs=n_change, inputs=n_change)\n",
    "    # im.input(lambda x: x + 1, outputs=n_input, inputs=n_input)\n",
    "    im.change(predict, outputs=im_preview, inputs=im, show_progress=\"hidden\")\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(server_name=\"0.0.0.0\", share=True)\n",
    "\n",
    "\n",
    "\n",
    "print(inputSketch)\n",
    "print(inputPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691754b-3359-4533-9ca1-3f63c6f9c3f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Section to test if the image is not empty and save them for later testing\n",
    "from PIL import Image\n",
    "# Quick empty check\n",
    "import numpy as np\n",
    "# print(inputSketch)\n",
    "# print(inputPrompt)\n",
    "\n",
    "\n",
    "countzero_in1 = not np.any(inputSketch)\n",
    "print(\"Whole array contains zeroes in array1 ?: \", countzero_in1)\n",
    "\n",
    "if countzero_in1 == False: \n",
    "    # Save the sketch as png\n",
    "    sketch_image = Image.fromarray(inputSketch)\n",
    "    sketch_image.save(\"saved_sketch_test.png\")\n",
    "    print(\"Sketch saved as 'saved_sketch.png'\")\n",
    "    \n",
    "    with open(\"saved_prompt_test.txt\", \"w\") as f:\n",
    "        f.write(inputPrompt)\n",
    "        print(\"Prompt saved as 'saved_prompt.txt'\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d53953-5e8b-40b3-9710-27076c9f136a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"A small iron sword.\",\n",
    "    \"A large two-handed sword.\",\n",
    "    \"A steel short sword.\",\n",
    "    \"A bronze sword.\",\n",
    "    \"A black sword with a red gem.\",\n",
    "    \"A rusty old sword.\",\n",
    "    \"A shining silver sword.\",\n",
    "    \"A sword with a leather grip.\",\n",
    "    \"A fire sword.\",\n",
    "    \"A sword with an icy blue blade.\",\n",
    "    \"A knight's sword with a golden hilt.\",\n",
    "    \"A plain copper sword.\",\n",
    "    \"A curved blade sword.\",\n",
    "    \"A sword with a green handle.\",\n",
    "    \"A glowing gold sword.\",\n",
    "    \"A small dagger-like sword.\",\n",
    "    \"A big heavy sword.\",\n",
    "    \"A thin, fast sword.\",\n",
    "    \"A red sword with jagged edges.\",\n",
    "    \"A royal sword with a blue gem.\"\n",
    "]\n",
    "\n",
    "# Smaller subset for intial tests\n",
    "prompts_subset = [\n",
    "    \"A small iron sword.\",\n",
    "    \"A large two-handed sword.\",\n",
    "    \"A steel short sword.\",\n",
    "    \"A bronze sword.\",\n",
    "    \"A black sword with a red gem.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dada5c8-5453-4e2f-aa6c-dcd2fade9eae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from diffusers import StableDiffusionXLControlNetPipeline, ControlNetModel, AutoencoderKL\n",
    "from diffusers import EulerAncestralDiscreteScheduler\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Base SDXL model\n",
    "base_model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "\n",
    "# ControlNet model (Scribble SDXL)\n",
    "controlnet_model_id = \"xinsir/controlnet-scribble-sdxl-1.0\"\n",
    "\n",
    "# LoRA file (Pixel-Art-XL)\n",
    "lora_file_path = \"pixel-art-xl-v1.1.safetensors\"\n",
    "\n",
    "# VAE for SDXL\n",
    "vae_id = \"madebyollin/sdxl-vae-fp16-fix\"\n",
    "\n",
    "# Load ControlNet model\n",
    "controlnet = ControlNetModel.from_pretrained(controlnet_model_id, torch_dtype=torch.float16)\n",
    "\n",
    "# Load SDXL pipeline with ControlNet\n",
    "pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
    "    base_model_id,\n",
    "    controlnet=controlnet,\n",
    "    vae=AutoencoderKL.from_pretrained(vae_id, torch_dtype=torch.float16),\n",
    "    safety_checker=None,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "# Load LoRA weights\n",
    "pipe.load_lora_weights(lora_file_path, adapter_name=\"pixel-art-xl\")\n",
    "\n",
    "# Enable GPU optimizations\n",
    "pipe.to(\"cuda\")\n",
    "\n",
    "# Scheduler\n",
    "pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# Image generation function with time tracking\n",
    "def generate_pixel_art(prompts, sketch_path, output_dir, num_images=4, log_file=\"time_log.txt\"):\n",
    "    # Open the log file for writing\n",
    "    with open(log_file, \"a\") as log:\n",
    "        # Load and process the sketch\n",
    "        if sketch_path:\n",
    "            sketch = Image.open(sketch_path).convert(\"L\")  # Convert to grayscale\n",
    "        else:\n",
    "            raise ValueError(\"Please provide a sketch path.\")\n",
    "\n",
    "        # Resize sketch to match SDXL resolution (1024x1024)\n",
    "        width, height = sketch.size\n",
    "        ratio = np.sqrt(1024.0 * 1024.0 / (width * height))\n",
    "        new_width, new_height = int(width * ratio), int(height * ratio)\n",
    "        sketch = sketch.resize((new_width, new_height))\n",
    "    \n",
    "    #loop through the prompt list to handel each prompt as a single unit is stead of the whole list\n",
    "        for prompt in prompts:\n",
    "            # Generate images\n",
    "            for i in range(num_images):\n",
    "                start_time = time.time()  # Start the timer\n",
    "\n",
    "                # ControlNet conditioning scale - LOWER this to make the AI follow the sketch LESS\n",
    "                controlnet_conditioning_scale = 0.5 # How much weight to assign to the conditioning inputs\n",
    "                guidance_scale = 8.0  # Increase this to make it follow the prompt more\n",
    "                num_inference_steps = 20  \n",
    "\n",
    "                # Generate the image\n",
    "                image = pipe(\n",
    "                    prompt=prompt,\n",
    "                    negative_prompt=\"lowres, blurry, bad anatomy, extra limbs\",\n",
    "                    image=sketch,\n",
    "                    controlnet_conditioning_scale=controlnet_conditioning_scale,  \n",
    "                    width=new_width,\n",
    "                    height=new_height,\n",
    "                    num_inference_steps=num_inference_steps, \n",
    "                    guidance_scale=guidance_scale, \n",
    "                ).images[0]\n",
    "\n",
    "\n",
    "                # Stop the timer\n",
    "                elapsed_time = time.time() - start_time\n",
    "\n",
    "                # Convert to RGBA and add transparency\n",
    "                image = image.convert(\"RGBA\")\n",
    "                data = np.array(image)\n",
    "                r, g, b, _ = data.T\n",
    "                white_areas = (r == 255) & (g == 255) & (b == 255)\n",
    "                data[..., -1][white_areas] = 0  # Make white areas transparent\n",
    "                image = Image.fromarray(data)\n",
    "\n",
    "                # Save the output\n",
    "                output_path = f\"{output_dir}/{prompt}_image_{i + 1}.png\"\n",
    "                image.save(output_path)\n",
    "\n",
    "                # Log the time taken\n",
    "                log.write(f\"Prompt: {prompt}, Image {i + 1}, Time: {elapsed_time:.2f} seconds\\n\")\n",
    "                print(f\"Generated image saved at: {output_path} (Time: {elapsed_time:.2f} seconds)\")\n",
    "\n",
    "\n",
    "\n",
    "# Path to the sketch\n",
    "sketch_path = \"your input sketch.png\" \n",
    "\n",
    "# Directory to save outputs\n",
    "output_dir = \"generated_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Log file\n",
    "log_file = \"time_log.txt\"\n",
    "if os.path.exists(log_file):\n",
    "    os.remove(log_file)  # Clear the log file if it already exists\n",
    "\n",
    "# Generate pixel art for each prompt\n",
    "for prompt in prompts:\n",
    "    generate_pixel_art(prompts_subset_1, sketch_path, output_dir, log_file=log_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199101c9-8d5a-4a98-8359-4fbc300f4777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Background remover test with another model \n",
    "from rembg import remove\n",
    "from PIL import Image\n",
    "\n",
    "# Load your input image\n",
    "input_path = 'AsmallIronSword3_second_run.png'\n",
    "output_path = 'A_Small_Iron_Sword_3_second_NBG.png'\n",
    "\n",
    "with Image.open(input_path) as img:\n",
    "    # Remove the background\n",
    "    img_no_bg = remove(img)\n",
    "    # Save the output image\n",
    "    img_no_bg.save(output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (new_ven)",
   "language": "python",
   "name": "new_ven"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
