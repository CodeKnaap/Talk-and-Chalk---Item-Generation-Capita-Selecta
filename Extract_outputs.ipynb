{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f475e-71e5-4e18-9005-3c00bc748d28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Ideally you might want to use a different way of storing and formating the outputs of the models\n",
    "\n",
    "import re\n",
    "\n",
    "def test_extract_sections(sample_text, prompts_to_match):\n",
    "    \"\"\"\n",
    "    Tests section extraction from sample text input.\n",
    "    \n",
    "    Parameters:\n",
    "    - sample_text (str): The raw multiline string to parse.\n",
    "    - prompts_to_match (list): List of prompts you expect to extract outputs for.\n",
    "    \n",
    "    Returns:\n",
    "    - List of dictionaries with prompt and extracted output.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Split by the delimiter line (assuming 5 or more dashes)\n",
    "    sections = re.split(r\"-{5,}\", sample_text)\n",
    "\n",
    "    print(f\"Found {len(sections)} sections.\")\n",
    "\n",
    "    for section in sections:\n",
    "        print(\"\\n--- Processing New Section ---\")\n",
    "\n",
    "        # Look for the prompt in this section\n",
    "        prompt_match = re.search(r\"Prompt:\\s*(.*?)\\s*Output:\", section, re.DOTALL)\n",
    "        if not prompt_match:\n",
    "            print(\"No prompt found in section.\")\n",
    "            continue\n",
    "        \n",
    "        prompt_text = prompt_match.group(1).strip()\n",
    "        print(f\"Found prompt: '{prompt_text}'\")\n",
    "\n",
    "        if prompt_text not in prompts_to_match:\n",
    "            print(f\"Prompt '{prompt_text}' not in list of prompts to match.\")\n",
    "            continue\n",
    "\n",
    "        # Extract the output text after ### OUTPUT:\n",
    "        output_match = re.search(r\"### OUTPUT:\\s*(.*)\", section, re.DOTALL)\n",
    "        if not output_match:\n",
    "            print(f\"No output found for prompt: {prompt_text}\")\n",
    "            continue\n",
    "        \n",
    "        model_output = output_match.group(1).strip()\n",
    "\n",
    "        print(f\"Extracted output for '{prompt_text}':\\n{model_output[:300]}...\")  # Show the first 300 chars\n",
    "\n",
    "        results.append({\n",
    "            \"Prompt\": prompt_text,\n",
    "            \"Output\": model_output\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af23d98b-4725-4cf2-abbd-003afcef8f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define prompts we expect to match\n",
    "prompts = [\n",
    "    \"A small iron sword.\",\n",
    "    \"A large two-handed sword.\",\n",
    "    \"A steel short sword.\",\n",
    "    \"A bronze sword.\",\n",
    "    \"A black sword with a red gem.\",\n",
    "    \"A rusty old sword.\",\n",
    "    \"A shining silver sword.\",\n",
    "    \"A sword with a leather grip.\",\n",
    "    \"A fire sword.\",\n",
    "    \"A sword with an icy blue blade.\",\n",
    "    \"A knight's sword with a golden hilt.\",\n",
    "    \"A plain copper sword.\",\n",
    "    \"A curved blade sword.\",\n",
    "    \"A sword with a green handle.\",\n",
    "    \"A glowing gold sword.\",\n",
    "    \"A small dagger-like sword.\",\n",
    "    \"A big heavy sword.\",\n",
    "    \"A thin, fast sword.\",\n",
    "    \"A red sword with jagged edges.\",\n",
    "    \"A royal sword with a blue gem.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d676ea-3a32-4b49-b1ea-df2d2a188fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Again you might want to change the method of storing results, the process of extracting and sorting the results was kind of cumbersome \n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def extract_model_output(folder_path, prompts):\n",
    "    \"\"\"\n",
    "    Reads all text files in a folder, extracts model outputs for given prompts, and structures data into a table.\n",
    "    \n",
    "    Parameters:\n",
    "    - folder_path (str): Path to the folder containing the text files.\n",
    "    - prompts (list of str): List of prompts to match in files.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Organized output table\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Known model names and regex for size detection\n",
    "    known_models = [\"Lamma\", \"Qwen\", \"StarCoder2\", \"Mixtral\"]\n",
    "\n",
    "    # Updated filename pattern to extract raw model name and run number\n",
    "    filename_pattern = re.compile(\n",
    "        r'([A-Za-z0-9]+)_?(?:Output|Outputs)?_?run(\\d+)\\.txt',\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Get all text files\n",
    "    files = sorted(os.listdir(folder_path))\n",
    "\n",
    "    for file in files:\n",
    "        if not file.endswith(\".txt\") or \"Time\" in file:\n",
    "            continue  # Skip unwanted files\n",
    "        \n",
    "        match = filename_pattern.match(file)\n",
    "        if not match:\n",
    "            print(f\"Skipped file: {file} (No match)\")\n",
    "            continue\n",
    "        \n",
    "        raw_model_name, run_number = match.groups()\n",
    "        run_number = int(run_number)\n",
    "\n",
    "        # Extract the model size\n",
    "        size_match = re.search(r\"(\\d+[Bb][s]?)\", raw_model_name)\n",
    "        extracted_size = size_match.group(1) if size_match else \"UnknownSize\"\n",
    "\n",
    "        # Detect the model name from known models\n",
    "        detected_model = \"UnknownModel\"\n",
    "        # Remove extracted size from raw model name to improve matching\n",
    "        model_name_no_size = raw_model_name.replace(extracted_size or \"\", \"\")\n",
    "        for model in known_models:\n",
    "            if model.lower() in model_name_no_size.lower():\n",
    "                detected_model = model\n",
    "                break\n",
    "\n",
    "        # Debug info if model name not detected\n",
    "        if detected_model == \"UnknownModel\":\n",
    "            print(f\"Unknown model detected in filename: {file}\")\n",
    "\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Split into sections by delimiter\n",
    "        sections = re.split(r\"-{5,}\", content)\n",
    "\n",
    "        for section in sections:\n",
    "            # Look for the prompt in the section\n",
    "            prompt_match = re.search(r\"Prompt:\\s*(.*?)\\s*Output:\", section, re.DOTALL)\n",
    "            if not prompt_match:\n",
    "                continue  # No prompt found in this section\n",
    "            \n",
    "            prompt_text = prompt_match.group(1).strip()\n",
    "\n",
    "            # Only process prompts we care about\n",
    "            if prompt_text not in prompts:\n",
    "                continue\n",
    "\n",
    "            # Extract the model output after ### OUTPUT:\n",
    "            output_match = re.search(r\"### OUTPUT:\\s*(.*)\", section, re.DOTALL)\n",
    "            if not output_match:\n",
    "                print(f\"Output not found for prompt: {prompt_text} in {file}\")\n",
    "                continue\n",
    "\n",
    "            model_output = output_match.group(1).strip()\n",
    "\n",
    "            # Append extracted data to the list\n",
    "            data.append([\n",
    "                run_number,\n",
    "                detected_model,\n",
    "                extracted_size,\n",
    "                prompt_text,\n",
    "                model_output\n",
    "            ])\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"Run\", \"Model\", \"Size\", \"Prompt\", \"Output\"])\n",
    "    df.sort_values([\"Prompt\", \"Run\", \"Model\", \"Size\"], inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601e943d-034e-42d5-b8f9-bfad8becff28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_path = \"your folder path here\"\n",
    "\n",
    "prompts = [\n",
    "    \"A small iron sword.\",\n",
    "    \"A large two-handed sword.\",\n",
    "    \"A steel short sword.\",\n",
    "    \"A bronze sword.\",\n",
    "    \"A black sword with a red gem.\",\n",
    "    \"A rusty old sword.\",\n",
    "    \"A shining silver sword.\",\n",
    "    \"A sword with a leather grip.\",\n",
    "    \"A fire sword.\",\n",
    "    \"A sword with an icy blue blade.\",\n",
    "    \"A knight's sword with a golden hilt.\",\n",
    "    \"A plain copper sword.\",\n",
    "    \"A curved blade sword.\",\n",
    "    \"A sword with a green handle.\",\n",
    "    \"A glowing gold sword.\",\n",
    "    \"A small dagger-like sword.\",\n",
    "    \"A big heavy sword.\",\n",
    "    \"A thin, fast sword.\",\n",
    "    \"A red sword with jagged edges.\",\n",
    "    \"A royal sword with a blue gem.\"\n",
    "]\n",
    "\n",
    "df_results = extract_model_output(folder_path, prompts)\n",
    "\n",
    "display(df_results)\n",
    "\n",
    "df_results.to_csv('name.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb899ead-b85a-4a0d-a61e-dcc801b8e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def compile_csv_files(folder_path):\n",
    "    \"\"\"\n",
    "    Reads all CSV files in a folder and merges them into one Pandas DataFrame, \n",
    "    ensuring the model name and size are correctly separated without overwriting existing sizes.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to the folder containing the CSV files.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Merged DataFrame with cleaned model names and sizes.\n",
    "    \"\"\"\n",
    "    all_dfs = []\n",
    "    \n",
    "    # Get all CSV files\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith(\".csv\")]\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Read CSV into DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Ensure 'Size' column exists\n",
    "        if \"Size\" not in df.columns:\n",
    "            df[\"Size\"] = \"UnknownSize\"\n",
    "\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into one\n",
    "    merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b01b7ca-0be2-4956-98d7-159eaf8e4402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Usage example\n",
    "folder_path = \"your folder path\"\n",
    "\n",
    "# Compile all CSVs\n",
    "df_combined = compile_csv_files(folder_path)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "display(df_combined)\n",
    "\n",
    "\n",
    "\n",
    "df_combined.to_csv('name.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e0f173-8b70-4907-8173-c518b9147ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (new_ven)",
   "language": "python",
   "name": "new_ven"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
